{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65d7431e-3ab0-495b-84fe-efb555eb6cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.26.4\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12687006-bf02-4a50-8a2a-08945b1192c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy==1.26.4\n",
      "  Using cached numpy-1.26.4-cp312-cp312-win_amd64.whl.metadata (61 kB)\n",
      "Using cached numpy-1.26.4-cp312-cp312-win_amd64.whl (15.5 MB)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.2.5\n",
      "    Uninstalling numpy-2.2.5:\n",
      "      Successfully uninstalled numpy-2.2.5\n",
      "Successfully installed numpy-1.26.4\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy==1.26.4\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ca6d1bd6-0fce-4da6-b8ee-b34b0f971ad5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-4.3.3-cp312-cp312-win_amd64.whl.metadata (8.2 kB)\n",
      "Collecting numpy<2.0,>=1.18.5 (from gensim)\n",
      "  Downloading numpy-1.26.4-cp312-cp312-win_amd64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gensim) (1.13.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gensim) (7.1.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n",
      "Downloading gensim-4.3.3-cp312-cp312-win_amd64.whl (24.0 MB)\n",
      "   ---------------------------------------- 0.0/24.0 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.8/24.0 MB 6.7 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 8.1/24.0 MB 28.0 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 8.7/24.0 MB 17.3 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 9.7/24.0 MB 13.4 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 10.5/24.0 MB 11.1 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 11.3/24.0 MB 10.1 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 12.3/24.0 MB 9.0 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 13.4/24.0 MB 8.2 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 14.2/24.0 MB 7.9 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 15.2/24.0 MB 7.4 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 16.0/24.0 MB 7.0 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 16.8/24.0 MB 6.8 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 17.8/24.0 MB 6.6 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 18.4/24.0 MB 6.3 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 18.9/24.0 MB 6.1 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 19.7/24.0 MB 5.8 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 20.2/24.0 MB 5.7 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 21.0/24.0 MB 5.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 21.5/24.0 MB 5.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 22.3/24.0 MB 5.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 22.8/24.0 MB 5.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  23.6/24.0 MB 5.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 24.0/24.0 MB 4.9 MB/s eta 0:00:00\n",
      "Downloading numpy-1.26.4-cp312-cp312-win_amd64.whl (15.5 MB)\n",
      "   ---------------------------------------- 0.0/15.5 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/15.5 MB 4.2 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 1.3/15.5 MB 3.4 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 1.8/15.5 MB 3.2 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 2.6/15.5 MB 3.3 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 3.4/15.5 MB 3.3 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 4.2/15.5 MB 3.3 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 4.7/15.5 MB 3.3 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 5.5/15.5 MB 3.3 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 6.3/15.5 MB 3.3 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 7.1/15.5 MB 3.3 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 7.9/15.5 MB 3.4 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 8.7/15.5 MB 3.4 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 9.4/15.5 MB 3.4 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 10.2/15.5 MB 3.4 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 11.0/15.5 MB 3.4 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 11.8/15.5 MB 3.5 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 12.6/15.5 MB 3.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 13.4/15.5 MB 3.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 14.2/15.5 MB 3.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 14.9/15.5 MB 3.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.5/15.5 MB 3.5 MB/s eta 0:00:00\n",
      "Installing collected packages: numpy, gensim\n",
      "\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   ---------------------------------------- 2/2 [gensim]\n",
      "\n",
      "Successfully installed gensim-4.3.3 numpy-1.26.4\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d547906-e999-4a00-8b81-265c066aa30b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cümle 1 - Lemmatized: ['advance', 'opinion', 'supreme', 'court', 'state', 'nevada', 'quashawn', 'saquan', 'sheridan']\n",
      "Cümle 1 - Stemmed: ['advanc', 'opinion', 'suprem', 'court', 'state', 'nevada', 'quashawn', 'saquan', 'sheridan']\n",
      "\n",
      "\n",
      "Cümle 2 - Lemmatized: ['appellant', 'v']\n",
      "Cümle 2 - Stemmed: ['appel', 'vs']\n",
      "\n",
      "\n",
      "Cümle 3 - Lemmatized: ['state', 'nevada', 'filed', 'respondent']\n",
      "Cümle 3 - Stemmed: ['state', 'nevada', 'file', 'respond']\n",
      "\n",
      "\n",
      "Cümle 4 - Lemmatized: ['apr', 'yl', 'mr', 'ha', 'rt', 'appeal', 'district', 'court', 'order', 'revoking', 'appellant', 'probation']\n",
      "Cümle 4 - Stemmed: ['apr', 'yl', 'mr', 'ha', 'rt', 'appeal', 'district', 'court', 'order', 'revok', 'appel', 'probat']\n",
      "\n",
      "\n",
      "Cümle 5 - Lemmatized: ['second', 'judicial', 'district', 'court', 'washoe', 'county', 'tammy', 'riggs', 'judge']\n",
      "Cümle 5 - Stemmed: ['second', 'judici', 'district', 'court', 'washo', 'counti', 'tammi', 'rigg', 'judg']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "\n",
    "# Gerekli bileşenleri indir (ilk çalıştırmada)\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Metni oku\n",
    "with open(\"karar_metni_2025-05-03_16-17-56.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    text = file.read()\n",
    "\n",
    "# Cümlelere ayır\n",
    "sentences = sent_tokenize(text)\n",
    "\n",
    "# Lemmatizer ve stemmer başlat\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# Stopword'leri tanımla\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Ön işleme fonksiyonu\n",
    "def preprocess_sentence(sentence):\n",
    "    tokens = word_tokenize(sentence)\n",
    "    filtered_tokens = [token.lower() for token in tokens if token.isalpha() and token.lower() not in stop_words]\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in filtered_tokens]\n",
    "    stemmed_tokens = [stemmer.stem(token) for token in filtered_tokens]\n",
    "    return lemmatized_tokens, stemmed_tokens\n",
    "\n",
    "# Cümleleri işle\n",
    "tokenized_corpus_lemmatized = []\n",
    "tokenized_corpus_stemmed = []\n",
    "\n",
    "for sentence in sentences:\n",
    "    lems, stems = preprocess_sentence(sentence)\n",
    "    tokenized_corpus_lemmatized.append(lems)\n",
    "    tokenized_corpus_stemmed.append(stems)\n",
    "\n",
    "# İlk 5 cümleyi yazdır\n",
    "for i in range(5):\n",
    "    print(f\"Cümle {i+1} - Lemmatized: {tokenized_corpus_lemmatized[i]}\")\n",
    "    print(f\"Cümle {i+1} - Stemmed: {tokenized_corpus_stemmed[i]}\")\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d60e7c1f-7593-4821-ba4b-79e73cc3d2c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cümle 1 - Lemmatized: ['advance', 'opinion', 'supreme', 'court', 'state', 'nevada', 'quashawn', 'saquan', 'sheridan']\n",
      "Cümle 1 - Stemmed: ['advanc', 'opinion', 'suprem', 'court', 'state', 'nevada', 'quashawn', 'saquan', 'sheridan']\n",
      "\n",
      "\n",
      "Cümle 2 - Lemmatized: ['appellant', 'v']\n",
      "Cümle 2 - Stemmed: ['appel', 'vs']\n",
      "\n",
      "\n",
      "Cümle 3 - Lemmatized: ['state', 'nevada', 'filed', 'respondent']\n",
      "Cümle 3 - Stemmed: ['state', 'nevada', 'file', 'respond']\n",
      "\n",
      "\n",
      "Cümle 4 - Lemmatized: ['apr', 'yl', 'mr', 'ha', 'rt', 'appeal', 'district', 'court', 'order', 'revoking', 'appellant', 'probation']\n",
      "Cümle 4 - Stemmed: ['apr', 'yl', 'mr', 'ha', 'rt', 'appeal', 'district', 'court', 'order', 'revok', 'appel', 'probat']\n",
      "\n",
      "\n",
      "Cümle 5 - Lemmatized: ['second', 'judicial', 'district', 'court', 'washoe', 'county', 'tammy', 'riggs', 'judge']\n",
      "Cümle 5 - Stemmed: ['second', 'judici', 'district', 'court', 'washo', 'counti', 'tammi', 'rigg', 'judg']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "\n",
    "# Dosya yolunu belirtelim\n",
    "file_path = 'karar_metni_2025-05-03_16-17-56.txt'\n",
    "\n",
    "# Dosya içeriğini okuma\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    text = file.read()\n",
    "\n",
    "# Cümlelere ayırma\n",
    "sentences = sent_tokenize(text)\n",
    "\n",
    "# Lemmatizer ve Stemmer'ı başlat\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# Stopwords listesini almak\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Kelimeleri tokenleştirip, lemmatize etme ve stemleme\n",
    "def preprocess_sentence(sentence):\n",
    "    tokens = word_tokenize(sentence)  # Cümleyi kelimelere ayır\n",
    "    # Sadece harf olan kelimeleri al ve stopword'leri çıkar\n",
    "    filtered_tokens = [token.lower() for token in tokens if token.isalpha() and token.lower() not in stop_words]\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in filtered_tokens]  # Lemmatize etme\n",
    "    stemmed_tokens = [stemmer.stem(token) for token in filtered_tokens]  # Stemleme\n",
    "    return lemmatized_tokens, stemmed_tokens\n",
    "\n",
    "# Her cümleyi tokenleştir, lemmatize et ve stemle\n",
    "tokenized_corpus_lemmatized = []\n",
    "tokenized_corpus_stemmed = []\n",
    "\n",
    "for sentence in sentences:\n",
    "    lemmatized_tokens, stemmed_tokens = preprocess_sentence(sentence)\n",
    "    tokenized_corpus_lemmatized.append(lemmatized_tokens)\n",
    "    tokenized_corpus_stemmed.append(stemmed_tokens)\n",
    "\n",
    "# Sonuçları yazdırmak\n",
    "for i in range(5):\n",
    "    print(f\"Cümle {i+1} - Lemmatized: {tokenized_corpus_lemmatized[i]}\")\n",
    "    print(f\"Cümle {i+1} - Stemmed: {tokenized_corpus_stemmed[i]}\")\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "accc0368-9432-4592-8387-d15d61dc7cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Her cümleyi tokenleştir, lemmatize et ve stemle\n",
    "tokenized_corpus_lemmatized = []\n",
    "tokenized_corpus_stemmed = []\n",
    "\n",
    "for sentence in sentences:\n",
    "    lemmatized_tokens, stemmed_tokens = preprocess_sentence(sentence)\n",
    "    tokenized_corpus_lemmatized.append(lemmatized_tokens)\n",
    "    tokenized_corpus_stemmed.append(stemmed_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1603c60-f626-4ba6-8fa8-fce36f1e3d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lemmatized_model_cbow_window2_dim100.model saved!\n",
      "lemmatized_model_skipgram_window2_dim100.model saved!\n",
      "lemmatized_model_cbow_window4_dim100.model saved!\n",
      "lemmatized_model_skipgram_window4_dim100.model saved!\n",
      "lemmatized_model_cbow_window2_dim300.model saved!\n",
      "lemmatized_model_skipgram_window2_dim300.model saved!\n",
      "lemmatized_model_cbow_window4_dim300.model saved!\n",
      "lemmatized_model_skipgram_window4_dim300.model saved!\n",
      "stemmed_model_cbow_window2_dim100.model saved!\n",
      "stemmed_model_skipgram_window2_dim100.model saved!\n",
      "stemmed_model_cbow_window4_dim100.model saved!\n",
      "stemmed_model_skipgram_window4_dim100.model saved!\n",
      "stemmed_model_cbow_window2_dim300.model saved!\n",
      "stemmed_model_skipgram_window2_dim300.model saved!\n",
      "stemmed_model_cbow_window4_dim300.model saved!\n",
      "stemmed_model_skipgram_window4_dim300.model saved!\n",
      "\n",
      "Lemmatized CBOW Window 2 Dim 100 Modeli - 'law' ile En Benzer 3 Kelime:\n",
      "Kelime: rpd, Benzerlik Skoru: 0.29109659790992737\n",
      "Kelime: riggs, Benzerlik Skoru: 0.28129276633262634\n",
      "Kelime: subsequently, Benzerlik Skoru: 0.24847494065761566\n",
      "\n",
      "Stemmed Skipgram Window 4 Dim 100 Modeli - 'law' ile En Benzer 3 Kelime:\n",
      "Kelime: avail, Benzerlik Skoru: 0.27150458097457886\n",
      "Kelime: discuss, Benzerlik Skoru: 0.2611159384250641\n",
      "Kelime: seek, Benzerlik Skoru: 0.2397446483373642\n",
      "\n",
      "Lemmatized Skipgram Window 2 Dim 300 Modeli - 'law' ile En Benzer 3 Kelime:\n",
      "Kelime: graduated, Benzerlik Skoru: 0.166525200009346\n",
      "Kelime: contention, Benzerlik Skoru: 0.16525952517986298\n",
      "Kelime: parole, Benzerlik Skoru: 0.16312585771083832\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Word2Vec modeli eğitmek için parametreler\n",
    "parameters = [\n",
    "    {'model_type': 'cbow', 'window': 2, 'vector_size': 100},\n",
    "    {'model_type': 'skipgram', 'window': 2, 'vector_size': 100},\n",
    "    {'model_type': 'cbow', 'window': 4, 'vector_size': 100},\n",
    "    {'model_type': 'skipgram', 'window': 4, 'vector_size': 100},\n",
    "    {'model_type': 'cbow', 'window': 2, 'vector_size': 300},\n",
    "    {'model_type': 'skipgram', 'window': 2, 'vector_size': 300},\n",
    "    {'model_type': 'cbow', 'window': 4, 'vector_size': 300},\n",
    "    {'model_type': 'skipgram', 'window': 4, 'vector_size': 300}\n",
    "]\n",
    "\n",
    "# Fonksiyon ile Word2Vec modeli eğitme ve kaydetme\n",
    "def train_and_save_model(corpus, params, model_name):\n",
    "    model = Word2Vec(\n",
    "        corpus,\n",
    "        vector_size=params['vector_size'],\n",
    "        window=params['window'],\n",
    "        min_count=1,\n",
    "        sg=1 if params['model_type'] == 'skipgram' else 0\n",
    "    )\n",
    "    model.save(f\"{model_name}_{params['model_type']}_window{params['window']}_dim{params['vector_size']}.model\")\n",
    "    print(f\"{model_name}_{params['model_type']}_window{params['window']}_dim{params['vector_size']}.model saved!\")\n",
    "\n",
    "# Lemmatize edilmiş corpus ile modelleri eğitme ve kaydetme\n",
    "for param in parameters:\n",
    "    train_and_save_model(tokenized_corpus_lemmatized, param, \"lemmatized_model\")\n",
    "\n",
    "# Stemlenmiş corpus ile modelleri eğitme ve kaydetme\n",
    "for param in parameters:\n",
    "    train_and_save_model(tokenized_corpus_stemmed, param, \"stemmed_model\")\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Model dosyalarını yüklemek\n",
    "model_1 = Word2Vec.load(\"lemmatized_model_cbow_window2_dim100.model\")\n",
    "model_2 = Word2Vec.load(\"stemmed_model_skipgram_window4_dim100.model\")\n",
    "model_3 = Word2Vec.load(\"lemmatized_model_skipgram_window2_dim300.model\")\n",
    "\n",
    "# 'txt' dosyanızdaki metni içeren kelimeler ile benzer kelimeleri yazdırmak\n",
    "def print_similar_words_from_txt(model, model_name, word_to_search):\n",
    "    similarity = model.wv.most_similar(word_to_search, topn=3)\n",
    "    print(f\"\\n{model_name} Modeli - '{word_to_search}' ile En Benzer 3 Kelime:\")\n",
    "    for word, score in similarity:\n",
    "        print(f\"Kelime: {word}, Benzerlik Skoru: {score}\")\n",
    "\n",
    "# Burada txt dosyanızdaki belirli bir kelimeyi arayabilirsiniz. Örneğin, 'law' kelimesi:\n",
    "word_to_search = \"law\"  # Dosyanızdaki önemli kelimeyi buraya yazabilirsiniz\n",
    "print_similar_words_from_txt(model_1, \"Lemmatized CBOW Window 2 Dim 100\", word_to_search)\n",
    "print_similar_words_from_txt(model_2, \"Stemmed Skipgram Window 4 Dim 100\", word_to_search)\n",
    "print_similar_words_from_txt(model_3, \"Lemmatized Skipgram Window 2 Dim 300\", word_to_search)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24192000-8abe-4140-b2bc-ef9631304a49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
